Touchpad Artificial Intelligence (Ver. 3.0)-XI:@0.176420:0.958597:0.488648:0.958597:0.488648:0.941370:0.176420:0.941370:0.008189:0.009106:0.009106:0.008189:0.009106:0.009106:0.009106:0.009106:0.003662:0.010924:0.005454:0.004553:0.003636:0.004095:0.004095:0.008189:0.003636:0.009106:0.003636:0.004553:0.004553:0.009106:0.004553:0.009106:0.003636:0.003636:0.003636:0.009106:0.009106:0.009106:0.008189:0.009106:0.004553:0.005454:0.010040:0.009106:0.004553:0.004553:0.004553:0.009106:0.004553:0.009106:0.005454:0.005749:0.011499:0.004553
228:@0.113927:0.958672:0.140411:0.958672:0.140411:0.942265:0.113927:0.942265:0.008828:0.008828:0.008828
Splitting data into training and testing sets is essential in machine learning for several reasons::@0.067333:0.058259:0.745762:0.058259:0.745762:0.041852:0.067333:0.041852:0.008697:0.009630:0.003964:0.003964:0.005552:0.005552:0.003964:0.009270:0.009647:0.004488:0.009647:0.008336:0.005552:0.008336:0.004488:0.003964:0.009270:0.005415:0.009598:0.004488:0.005552:0.005700:0.008336:0.003964:0.009270:0.003964:0.009270:0.009647:0.004488:0.008336:0.009270:0.009647:0.004488:0.005400:0.008566:0.006944:0.005552:0.003964:0.009270:0.009647:0.004488:0.006944:0.008566:0.005552:0.006944:0.004488:0.003964:0.006944:0.004488:0.008566:0.006944:0.006944:0.008566:0.009270:0.005552:0.003964:0.008336:0.003964:0.004488:0.003964:0.009270:0.004488:0.014102:0.008336:0.007567:0.009270:0.003964:0.009270:0.008566:0.004488:0.003964:0.008566:0.008336:0.005680:0.009270:0.003964:0.009270:0.009647:0.004488:0.005126:0.009598:0.005700:0.004488:0.006944:0.008566:0.007742:0.008566:0.005700:0.008336:0.003964:0.004488:0.005470:0.008566:0.008336:0.006944:0.009598:0.009270:0.006944:0.003554
• •:@0.074867:0.080371:0.074867:0.080371:0.074867:0.064910:0.074867:0.064910:0.004095:-0.011628:0.007534
  Evaluation of model performance: :@0.100089:0.080768:0.371190:0.080768:0.371190:0.064121:0.100089:0.064121:0.004520:-0.004520:0.008713:0.008633:0.008811:0.004651:0.009909:0.008811:0.006371:0.004651:0.010007:0.009909:0.005916:0.009765:0.006273:0.005906:0.015002:0.010007:0.010138:0.008861:0.004651:0.005913:0.010154:0.008861:0.006928:0.006273:0.010007:0.006576:0.015002:0.008811:0.009909:0.007862:0.008861:0.004438:0.004520
By splitting the dataset, you can evaluate how well your model generalises :@0.372572:0.080768:0.926763:0.080768:0.926763:0.064361:0.372572:0.064361:0.009385:0.007927:0.005863:0.006944:0.009630:0.003964:0.003964:0.005552:0.005552:0.003964:0.009270:0.009647:0.005863:0.005552:0.009270:0.008566:0.005855:0.009647:0.008336:0.005552:0.008336:0.006944:0.008566:0.005552:0.003554:0.005845:0.007847:0.009598:0.009270:0.005855:0.007567:0.008336:0.009270:0.005854:0.008566:0.007549:0.008336:0.003964:0.009270:0.008336:0.005416:0.008566:0.005863:0.009270:0.009598:0.011841:0.005852:0.011755:0.008566:0.003964:0.003964:0.005863:0.007845:0.009598:0.009270:0.005700:0.005850:0.014102:0.009598:0.009647:0.008566:0.003964:0.005863:0.009647:0.008566:0.009270:0.008566:0.005700:0.008336:0.003964:0.003964:0.006944:0.008566:0.006944:0.004488
to new, unseen data. The testing set serves as a proxy for real-world data, allowing you to assess the model’s :@0.100089:0.099699:0.926742:0.099699:0.926742:0.083292:0.100089:0.083292:0.005421:0.009598:0.006650:0.009270:0.008566:0.011113:0.003554:0.006650:0.009270:0.009270:0.006944:0.008566:0.008566:0.009270:0.006650:0.009647:0.008336:0.005552:0.008336:0.003554:0.006638:0.008582:0.009270:0.008566:0.006650:0.005423:0.008566:0.006944:0.005552:0.003964:0.009270:0.009647:0.006650:0.006944:0.008566:0.005552:0.006650:0.006944:0.008566:0.006355:0.007750:0.008566:0.006944:0.006650:0.008336:0.006944:0.006650:0.008336:0.006650:0.009630:0.005477:0.009396:0.007518:0.007927:0.006650:0.005126:0.009598:0.005700:0.006650:0.005478:0.008566:0.008336:0.003964:0.006551:0.011786:0.009598:0.005700:0.003964:0.009647:0.006650:0.009647:0.008336:0.005552:0.008336:0.003554:0.006638:0.008336:0.003964:0.003964:0.009598:0.011841:0.003964:0.009270:0.009647:0.006650:0.007845:0.009598:0.009270:0.006650:0.005421:0.009598:0.006650:0.008336:0.006944:0.006944:0.008566:0.006944:0.006944:0.006669:0.005552:0.009270:0.008566:0.006650:0.014102:0.009598:0.009647:0.008566:0.003964:0.002819:0.006944:0.004488
performance accurately. :@0.100089:0.118630:0.276662:0.118630:0.276662:0.102223:0.100089:0.102223:0.009630:0.008566:0.006003:0.005126:0.009598:0.005662:0.014102:0.008336:0.009270:0.007567:0.008566:0.004488:0.008336:0.007567:0.007567:0.009270:0.005700:0.008336:0.005402:0.008566:0.003964:0.006912:0.003554:0.004488
• •:@0.074866:0.140742:0.074866:0.140742:0.074866:0.125282:0.074866:0.125282:0.004095:-0.011628:0.007534
 :@0.100089:0.141139:0.104577:0.141139:0.104577:0.124732:0.100089:0.124732:0.004488
Avoiding overfitting: :@0.100089:0.141139:0.266161:0.141139:0.266161:0.124492:0.100089:0.124492:0.011157:0.008716:0.010007:0.004651:0.010138:0.004651:0.009909:0.010138:0.004864:0.010007:0.008721:0.008861:0.006926:0.006273:0.004651:0.006371:0.006371:0.004651:0.009909:0.010138:0.004438:0.004520
Overfitting occurs when a model learns to memorise the training data’s patterns instead of :@0.266524:0.141139:0.926762:0.141139:0.926762:0.124732:0.266524:0.124732:0.012349:0.007747:0.008566:0.005700:0.004545:0.004545:0.005552:0.005552:0.003964:0.009270:0.009647:0.004805:0.009598:0.007567:0.007567:0.009270:0.005801:0.006944:0.004827:0.011841:0.009270:0.008566:0.009270:0.004812:0.008336:0.004818:0.014102:0.009598:0.009647:0.008566:0.003964:0.004825:0.003964:0.008566:0.008336:0.005659:0.009270:0.006944:0.004825:0.005423:0.009598:0.004820:0.014102:0.008566:0.014102:0.009598:0.005700:0.003964:0.006944:0.008566:0.004832:0.005552:0.009270:0.008566:0.004817:0.005552:0.005700:0.008336:0.003964:0.009270:0.003964:0.009270:0.009647:0.004812:0.009647:0.008336:0.005552:0.008336:0.002804:0.006944:0.004825:0.009413:0.008336:0.005552:0.005418:0.008566:0.005660:0.009270:0.006944:0.004825:0.003964:0.009270:0.006944:0.005429:0.008566:0.008336:0.009647:0.004815:0.009300:0.005126:0.004488
learning the underlying relationships. Splitting the data ensures that you can evaluate the model’s performance on :@0.100089:0.160070:0.926781:0.160070:0.926781:0.143663:0.100089:0.143663:0.003964:0.008566:0.008336:0.005660:0.009270:0.003964:0.009270:0.009647:0.004429:0.005552:0.009270:0.008566:0.004425:0.009270:0.009270:0.009647:0.008566:0.005700:0.003964:0.007927:0.003964:0.009270:0.009647:0.004422:0.005478:0.008566:0.003964:0.008336:0.005552:0.003964:0.009598:0.009270:0.006944:0.009270:0.003964:0.009630:0.006944:0.003554:0.004438:0.008697:0.009630:0.003964:0.003964:0.005552:0.005552:0.003964:0.009270:0.009647:0.004438:0.005552:0.009270:0.008566:0.004425:0.009647:0.008336:0.005552:0.008336:0.004419:0.008566:0.009270:0.006944:0.009270:0.005477:0.008566:0.006944:0.004438:0.005552:0.009270:0.008336:0.005552:0.004420:0.007845:0.009598:0.009270:0.004427:0.007567:0.008336:0.009270:0.004424:0.008566:0.007549:0.008336:0.003964:0.009270:0.008336:0.005418:0.008566:0.004429:0.005552:0.009270:0.008566:0.004425:0.014102:0.009598:0.009647:0.008566:0.003964:0.002819:0.006944:0.004438:0.009630:0.008566:0.006003:0.005126:0.009598:0.005662:0.014102:0.008336:0.009270:0.007567:0.008566:0.004427:0.009598:0.009270:0.004488
data it has not seen during training. If the model performs well on the testing set, it indicates that it has learned to :@0.100089:0.179002:0.926799:0.179002:0.926799:0.162595:0.100089:0.162595:0.009647:0.008336:0.005552:0.008336:0.004438:0.003964:0.005552:0.004455:0.009270:0.008336:0.006944:0.004455:0.009270:0.009598:0.005552:0.004445:0.006944:0.008566:0.008566:0.009270:0.004455:0.009647:0.009270:0.005700:0.003964:0.009270:0.009647:0.004440:0.005552:0.005700:0.008336:0.003964:0.009270:0.003964:0.009270:0.009647:0.003554:0.004437:0.004357:0.005126:0.004455:0.005552:0.009270:0.008566:0.004445:0.014102:0.009598:0.009647:0.008566:0.003964:0.004455:0.009630:0.008566:0.006004:0.005126:0.009598:0.005660:0.014102:0.006944:0.004455:0.011756:0.008566:0.003964:0.003964:0.004455:0.009598:0.009270:0.004455:0.005552:0.009270:0.008566:0.004445:0.005421:0.008566:0.006944:0.005552:0.003964:0.009270:0.009647:0.004455:0.006944:0.008566:0.005552:0.003554:0.004455:0.003964:0.005552:0.004455:0.003964:0.009270:0.009647:0.003964:0.007567:0.008336:0.005420:0.008566:0.006944:0.004455:0.005552:0.009270:0.008336:0.005552:0.004442:0.003964:0.005552:0.004455:0.009270:0.008336:0.006944:0.004455:0.003964:0.008566:0.008336:0.005662:0.009270:0.008566:0.009647:0.004445:0.005421:0.009598:0.004488
generalise rather than memorise.:@0.100089:0.197933:0.337720:0.197933:0.337720:0.181526:0.100089:0.181526:0.009647:0.008566:0.009270:0.008566:0.005700:0.008336:0.003964:0.003964:0.006944:0.008566:0.004488:0.005700:0.008336:0.005552:0.009270:0.008566:0.005700:0.004488:0.005552:0.009270:0.008336:0.009270:0.004488:0.014102:0.008566:0.014102:0.009598:0.005700:0.003964:0.006944:0.008566:0.003554
• •:@0.074867:0.220045:0.074867:0.220045:0.074867:0.204584:0.074867:0.204584:0.004095:-0.011628:0.007534
 :@0.100089:0.220442:0.104577:0.220442:0.104577:0.204035:0.100089:0.204035:0.004488
Model selection: :@0.100089:0.220442:0.232438:0.220442:0.232438:0.203795:0.100089:0.203795:0.015674:0.010007:0.010138:0.008861:0.004651:0.005667:0.007206:0.008861:0.004651:0.008861:0.007862:0.006371:0.004651:0.010020:0.009909:0.004438:0.004520
When comparing different models or algorithms, it’s crucial to have a standardised testing set :@0.233571:0.220442:0.926778:0.220442:0.926778:0.204035:0.233571:0.204035:0.015297:0.009270:0.008566:0.009270:0.005618:0.007567:0.009598:0.014102:0.009414:0.008336:0.005700:0.003964:0.009270:0.009647:0.005606:0.009647:0.003964:0.005126:0.005126:0.008566:0.005478:0.008566:0.009270:0.005552:0.005618:0.014102:0.009598:0.009647:0.008566:0.003964:0.006944:0.005618:0.009598:0.005700:0.005610:0.008336:0.003964:0.009647:0.009598:0.005700:0.003964:0.005552:0.009270:0.014102:0.006944:0.003554:0.005618:0.003964:0.005552:0.002817:0.006944:0.005618:0.007567:0.005700:0.009270:0.007567:0.003964:0.008336:0.003964:0.005618:0.005423:0.009598:0.005618:0.009270:0.008336:0.007745:0.008566:0.005618:0.008336:0.005618:0.006944:0.005552:0.008336:0.009270:0.009647:0.008336:0.005470:0.009647:0.003964:0.006944:0.008566:0.009647:0.005618:0.005421:0.008566:0.006944:0.005552:0.003964:0.009270:0.009647:0.005618:0.006944:0.008566:0.005552:0.004488
for fair comparison. Splitting the data ensures that each model is evaluated on the same set of unseen examples, :@0.100089:0.239373:0.926775:0.239373:0.926775:0.222966:0.100089:0.222966:0.005126:0.009598:0.005700:0.005128:0.005126:0.008336:0.003964:0.005700:0.005130:0.007567:0.009598:0.014102:0.009416:0.008336:0.005700:0.003964:0.006944:0.009598:0.009270:0.003554:0.005130:0.008697:0.009630:0.003964:0.003964:0.005552:0.005552:0.003964:0.009270:0.009647:0.005143:0.005552:0.009270:0.008566:0.005131:0.009647:0.008336:0.005552:0.008336:0.005125:0.008566:0.009270:0.006944:0.009270:0.005480:0.008566:0.006944:0.005143:0.005552:0.009270:0.008336:0.005552:0.005126:0.008566:0.008336:0.007567:0.009270:0.005128:0.014102:0.009598:0.009647:0.008566:0.003964:0.005143:0.003964:0.006944:0.005143:0.008566:0.007549:0.008336:0.003964:0.009270:0.008336:0.005416:0.008566:0.009647:0.005133:0.009598:0.009270:0.005133:0.005552:0.009270:0.008566:0.005131:0.006944:0.008336:0.014102:0.008566:0.005143:0.006944:0.008566:0.005552:0.005143:0.009301:0.005126:0.005135:0.009270:0.009270:0.006944:0.008566:0.008566:0.009270:0.005135:0.008566:0.007518:0.008336:0.014102:0.009630:0.003964:0.008566:0.006944:0.003554:0.004488
allowing you to make informed decisions about which model performs best.:@0.100089:0.258304:0.648526:0.258304:0.648526:0.241897:0.100089:0.241897:0.008336:0.003964:0.003964:0.009598:0.011841:0.003964:0.009270:0.009647:0.004488:0.007840:0.009598:0.009270:0.004488:0.005418:0.009598:0.004488:0.014102:0.008336:0.007812:0.008566:0.004488:0.003964:0.009270:0.005126:0.009598:0.005660:0.014102:0.008566:0.009647:0.004488:0.009647:0.008566:0.007567:0.003964:0.006944:0.003964:0.009598:0.009270:0.006944:0.004488:0.008336:0.009630:0.009598:0.009270:0.005552:0.004488:0.011841:0.009270:0.003964:0.007567:0.009270:0.004488:0.014102:0.009598:0.009647:0.008566:0.003964:0.004488:0.009630:0.008566:0.005998:0.005126:0.009598:0.005660:0.014102:0.006944:0.004488:0.009630:0.008566:0.006944:0.005552:0.003554
Let us now split the data into a training set and a testing set.:@0.067333:0.280807:0.502610:0.280807:0.502610:0.264400:0.067333:0.264400:0.007714:0.008566:0.005552:0.004488:0.009270:0.006944:0.004488:0.009270:0.009598:0.011841:0.004488:0.006944:0.009630:0.003964:0.003964:0.005552:0.004488:0.005552:0.009270:0.008566:0.004488:0.009647:0.008336:0.005552:0.008336:0.004488:0.003964:0.009270:0.005397:0.009598:0.004488:0.008336:0.004488:0.005552:0.005700:0.008336:0.003964:0.009270:0.003964:0.009270:0.009647:0.004488:0.006944:0.008566:0.005552:0.004488:0.008336:0.009270:0.009647:0.004488:0.008336:0.004488:0.005392:0.008566:0.006944:0.005552:0.003964:0.009270:0.009647:0.004488:0.006944:0.008566:0.005552:0.003554
Program 61: To split the data of the IRIS dataset into training set and testing set:@0.081254:0.310466:0.696741:0.310466:0.696741:0.293819:0.081254:0.293819:0.010056:0.006458:0.010007:0.010138:0.006519:0.008811:0.015002:0.004520:0.009417:0.009417:0.004438:0.004520:0.008137:0.010007:0.004520:0.007206:0.010154:0.004651:0.004651:0.006371:0.004520:0.006371:0.009860:0.008861:0.004520:0.010138:0.008811:0.006371:0.008811:0.004520:0.009783:0.006273:0.004520:0.006371:0.009860:0.008861:0.004520:0.005192:0.010695:0.005192:0.009188:0.004520:0.010138:0.008811:0.006371:0.008811:0.007206:0.008861:0.006371:0.004520:0.004651:0.009909:0.006309:0.010007:0.004520:0.006371:0.006519:0.008811:0.004651:0.009909:0.004651:0.009909:0.010138:0.004520:0.007206:0.008861:0.006371:0.004520:0.008811:0.009909:0.010138:0.004520:0.006324:0.008861:0.007206:0.006371:0.004651:0.009909:0.010138:0.004520:0.007206:0.008861:0.006371
from sklearn.model_selection import train_test_split:@0.105003:0.339458:0.616001:0.339458:0.616001:0.325179:0.105003:0.325179:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
# load dataset:@0.105003:0.359550:0.242579:0.359550:0.242579:0.345271:0.105003:0.345271:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
from sklearn.datasets import load_iris:@0.105003:0.379642:0.478425:0.379642:0.478425:0.365363:0.105003:0.365363:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
iris = load_iris():@0.105003:0.399735:0.281887:0.399735:0.281887:0.385456:0.105003:0.385456:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
# separate the data into features and target:@0.105003:0.426983:0.537386:0.426983:0.537386:0.412704:0.105003:0.412704:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
X = iris.data:@0.105003:0.447075:0.232752:0.447075:0.232752:0.432796:0.105003:0.432796:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
y = iris.target:@0.105003:0.467168:0.252406:0.467168:0.252406:0.452889:0.105003:0.452889:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
# Split the data: 80% for training, 20% for testing:@0.105003:0.494416:0.606174:0.494416:0.606174:0.480137:0.105003:0.480137:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
X_train, X_test, y_train, y_test = train_test_split(X,  y, test_size=0.2,  random_:@0.105003:0.514508:0.922248:0.514508:0.922248:0.500229:0.105003:0.500229:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.013709:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.013709:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.013709:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.013709:0.009827:0.013709:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.003906:0.009827:0.009827:0.013709:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.003898:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
state=1):@0.105003:0.532809:0.183618:0.532809:0.183618:0.518530:0.105003:0.518530:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
# Splitting the data into training and testing sets (80% training, 20% testing):@0.105003:0.560057:0.881327:0.560057:0.881327:0.545778:0.105003:0.545778:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
X_train, X_test, y_train, y_test = train_test_split(X,  y, test_size=0.2,  random_:@0.105003:0.580149:0.922248:0.580149:0.922248:0.565870:0.105003:0.565870:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.013709:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.013709:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.013709:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.013709:0.009827:0.013709:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.003906:0.009827:0.009827:0.013709:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.003898:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
state=42):@0.105003:0.598449:0.193445:0.598449:0.193445:0.584170:0.105003:0.584170:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
# Printing the shapes of the training and testing sets to verify the split:@0.105003:0.625698:0.832193:0.625698:0.832193:0.611419:0.105003:0.611419:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
print(\Training set - Features:\, X_train.shape, \ Labels:\, y_train.shape):@0.105003:0.645790:0.842020:0.645790:0.842020:0.631511:0.105003:0.631511:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
print(\Testing set - Features:\, X_test.shape, \ Labels:\, y_test.shape):@0.105003:0.665882:0.812539:0.665882:0.812539:0.651603:0.105003:0.651603:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
Output::@0.067333:0.683070:0.126900:0.683070:0.126900:0.666423:0.067333:0.666423:0.012415:0.009909:0.006371:0.010154:0.009909:0.006371:0.004438
Training set - Features: (120, 4)  Labels: (120,):@0.100089:0.709109:0.589469:0.709109:0.589469:0.694830:0.100089:0.694830:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
Testing set - Features: (30, 4)  Labels: (30,):@0.100089:0.731612:0.559497:0.731612:0.559497:0.717333:0.100089:0.717333:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
Adding a Classifier: KNeighborsClassifier :@0.067333:0.763576:0.447594:0.763576:0.447594:0.746817:0.067333:0.746817:0.013817:0.012166:0.012166:0.005582:0.011891:0.012166:0.005424:0.010574:0.005424:0.012264:0.005582:0.010574:0.008648:0.008648:0.005582:0.006555:0.006555:0.010633:0.007822:0.005326:0.005424:0.012755:0.015526:0.010633:0.005582:0.012166:0.011832:0.012185:0.012008:0.007822:0.008648:0.012264:0.005582:0.010574:0.008648:0.008648:0.005582:0.006555:0.006555:0.010633:0.007822:0.005424
Scikit-learn provides a diverse set of machine learning (ML) methods, each following a standard interface for tasks such :@0.067333:0.782952:0.926760:0.782952:0.926760:0.766545:0.067333:0.766545:0.008697:0.007567:0.003964:0.008140:0.003964:0.004656:0.006551:0.003964:0.008566:0.008336:0.005659:0.009270:0.004419:0.009630:0.005477:0.009598:0.007845:0.003964:0.009647:0.008566:0.006944:0.004425:0.008336:0.004417:0.009647:0.003964:0.007750:0.008566:0.005804:0.006944:0.008566:0.004424:0.006944:0.008566:0.005552:0.004422:0.009301:0.005126:0.004419:0.014102:0.008336:0.007567:0.009270:0.003964:0.009270:0.008566:0.004420:0.003964:0.008566:0.008336:0.005660:0.009270:0.003964:0.009270:0.009647:0.004419:0.004946:0.014708:0.007714:0.004933:0.004419:0.014102:0.008566:0.005552:0.009270:0.009598:0.009647:0.006944:0.003554:0.004420:0.008566:0.008336:0.007567:0.009270:0.004412:0.005126:0.009598:0.003964:0.003964:0.009598:0.011841:0.003964:0.009270:0.009647:0.004417:0.008336:0.004417:0.006944:0.005552:0.008336:0.009270:0.009647:0.008336:0.005470:0.009647:0.004419:0.003964:0.009270:0.005423:0.008566:0.006006:0.005126:0.008336:0.007567:0.008566:0.004414:0.005126:0.009598:0.005700:0.004412:0.005552:0.008336:0.006944:0.008140:0.006944:0.004425:0.006944:0.009270:0.007567:0.009270:0.004488
as model fitting, prediction, and performance metrics like accuracy and recall. One of the most important and commonly :@0.067333:0.801883:0.926763:0.801883:0.926763:0.785476:0.067333:0.785476:0.008336:0.006944:0.003728:0.014102:0.009598:0.009647:0.008566:0.003964:0.003728:0.005126:0.003964:0.005552:0.005552:0.003964:0.009270:0.009647:0.003554:0.003723:0.009630:0.005475:0.008566:0.009647:0.003964:0.007567:0.005552:0.003964:0.009598:0.009270:0.003554:0.003719:0.008336:0.009270:0.009647:0.003724:0.009630:0.008566:0.006003:0.005126:0.009598:0.005660:0.014102:0.008336:0.009270:0.007567:0.008566:0.003724:0.014102:0.008566:0.005552:0.005700:0.003964:0.007567:0.006944:0.003729:0.003964:0.003964:0.007819:0.008566:0.003724:0.008336:0.007567:0.007567:0.009270:0.005700:0.008336:0.007567:0.007927:0.003711:0.008336:0.009270:0.009647:0.003718:0.005478:0.008566:0.007567:0.008336:0.003964:0.003964:0.003554:0.003723:0.012349:0.009270:0.008566:0.003721:0.009301:0.005126:0.003726:0.005552:0.009270:0.008566:0.003721:0.014102:0.009598:0.006944:0.005552:0.003733:0.003964:0.014102:0.009630:0.009598:0.006171:0.005552:0.008336:0.009270:0.005552:0.003716:0.008336:0.009270:0.009647:0.003719:0.007567:0.009598:0.014102:0.014102:0.009598:0.009270:0.003964:0.007927:0.004488
used method is K-Nearest Neighbors (KNN) classifier. :@0.067333:0.820815:0.455399:0.820815:0.455399:0.804408:0.067333:0.804408:0.009270:0.006944:0.008566:0.009647:0.004488:0.014102:0.008566:0.005552:0.009270:0.009598:0.009647:0.004488:0.003964:0.006944:0.004488:0.009499:0.006551:0.012251:0.008566:0.008336:0.005477:0.008566:0.006944:0.005552:0.004488:0.012251:0.008566:0.003964:0.009647:0.009270:0.009630:0.009598:0.005804:0.006944:0.004488:0.004946:0.009499:0.012251:0.012251:0.004946:0.004488:0.007567:0.003964:0.008336:0.006944:0.006944:0.003964:0.005126:0.003964:0.008566:0.004345:0.003554:0.004488
K-Nearest Neighbors (KNN) is a simple classification algorithm used in supervised learning. It’s primarily employed for :@0.067333:0.843317:0.926762:0.843317:0.926762:0.826910:0.067333:0.826910:0.009499:0.006551:0.012251:0.008566:0.008336:0.005474:0.008566:0.006944:0.005552:0.004873:0.012251:0.008566:0.003964:0.009647:0.009270:0.009630:0.009598:0.005801:0.006944:0.004876:0.004946:0.009499:0.012251:0.012251:0.004946:0.004866:0.003964:0.006944:0.004876:0.008336:0.004868:0.006944:0.003964:0.014102:0.009630:0.003964:0.008566:0.004884:0.007567:0.003964:0.008336:0.006944:0.006944:0.003964:0.005126:0.003964:0.007567:0.008336:0.005552:0.003964:0.009598:0.009270:0.004879:0.008336:0.003964:0.009647:0.009598:0.005700:0.003964:0.005552:0.009270:0.014102:0.004866:0.009270:0.006944:0.008566:0.009647:0.004873:0.003964:0.009270:0.004871:0.006944:0.009270:0.009630:0.008566:0.006351:0.007845:0.003964:0.006944:0.008566:0.009647:0.004876:0.003964:0.008566:0.008336:0.005660:0.009270:0.003964:0.009270:0.009647:0.003554:0.004866:0.004357:0.005552:0.002815:0.006944:0.004876:0.009630:0.005700:0.003964:0.014102:0.008336:0.005700:0.003964:0.003964:0.007927:0.004866:0.008566:0.014102:0.009630:0.003964:0.009598:0.007850:0.008566:0.009647:0.004868:0.005126:0.009598:0.005700:0.004488
classification tasks, although it can also be adapted for regression. The goal of this classifier is to assign labels to new :@0.067333:0.862249:0.926734:0.862249:0.926734:0.845842:0.067333:0.845842:0.007567:0.003964:0.008336:0.006944:0.006944:0.003964:0.005126:0.003964:0.007567:0.008336:0.005552:0.003964:0.009598:0.009270:0.005189:0.005552:0.008336:0.006944:0.008140:0.006944:0.003554:0.005175:0.008336:0.003964:0.005552:0.009270:0.009598:0.009270:0.009647:0.009270:0.005175:0.003964:0.005552:0.005175:0.007567:0.008336:0.009270:0.005175:0.008336:0.003964:0.006944:0.009598:0.005185:0.009630:0.008566:0.005175:0.008336:0.009647:0.008336:0.009630:0.005411:0.008566:0.009647:0.005175:0.005126:0.009598:0.005700:0.005175:0.005478:0.008566:0.009647:0.005475:0.008566:0.006944:0.006944:0.003964:0.009598:0.009270:0.003554:0.005187:0.008582:0.009270:0.008566:0.005175:0.009647:0.009378:0.008336:0.003964:0.005175:0.009300:0.005126:0.005175:0.005552:0.009270:0.003964:0.006944:0.005185:0.007567:0.003964:0.008336:0.006944:0.006944:0.003964:0.005126:0.003964:0.008566:0.005700:0.005189:0.003964:0.006944:0.005190:0.005421:0.009598:0.005175:0.008336:0.006944:0.006944:0.003964:0.009647:0.009270:0.005187:0.003964:0.008336:0.009630:0.008566:0.003964:0.006944:0.005185:0.005423:0.009598:0.005175:0.009270:0.008566:0.011841:0.004488
occurrences based on their resemblance to those in the training set. :@0.067333:0.881180:0.560468:0.881180:0.560468:0.864773:0.067333:0.864773:0.009598:0.007567:0.007567:0.009270:0.005700:0.005467:0.008566:0.009270:0.007567:0.008566:0.006944:0.004488:0.009413:0.008336:0.006944:0.008566:0.009647:0.004488:0.009598:0.009270:0.004488:0.005552:0.009270:0.008566:0.003964:0.005700:0.004488:0.005464:0.008566:0.006944:0.008566:0.014102:0.009630:0.003964:0.008336:0.009270:0.007567:0.008566:0.004488:0.005424:0.009598:0.004488:0.005552:0.009270:0.009598:0.006944:0.008566:0.004488:0.003964:0.009270:0.004488:0.005552:0.009270:0.008566:0.004488:0.005552:0.005700:0.008336:0.003964:0.009270:0.003964:0.009270:0.009647:0.004488:0.006944:0.008566:0.005552:0.003554:0.004488
KNN produces predictions based on the majority class of the ‘k’ nearest data points. This method is very useful for small :@0.067333:0.903683:0.926739:0.903683:0.926739:0.887276:0.067333:0.887276:0.009499:0.012251:0.012251:0.004078:0.009630:0.005477:0.009598:0.009647:0.009270:0.007567:0.008566:0.006944:0.004078:0.009630:0.005475:0.008566:0.009647:0.003964:0.007567:0.005552:0.003964:0.009598:0.009270:0.006944:0.004078:0.009413:0.008336:0.006944:0.008566:0.009647:0.004078:0.009598:0.009270:0.004078:0.005552:0.009270:0.008566:0.004078:0.014102:0.008336:0.003964:0.009598:0.005700:0.003964:0.005552:0.007927:0.004078:0.007567:0.003964:0.008336:0.006944:0.006944:0.004088:0.009300:0.005126:0.004078:0.005552:0.009270:0.008566:0.004078:0.003751:0.008140:0.003751:0.004078:0.009270:0.008566:0.008336:0.005472:0.008566:0.006944:0.005552:0.004078:0.009647:0.008336:0.005552:0.008336:0.004068:0.009630:0.009598:0.003964:0.009270:0.005552:0.006944:0.003554:0.004078:0.008582:0.009270:0.003964:0.006944:0.004078:0.014102:0.008566:0.005552:0.009270:0.009598:0.009647:0.004078:0.003964:0.006944:0.004088:0.007749:0.008566:0.006350:0.007927:0.004078:0.009270:0.006944:0.008566:0.005126:0.009270:0.003964:0.004078:0.005126:0.009598:0.005700:0.004078:0.006944:0.014102:0.008336:0.003964:0.003964:0.004488
to medium-sized datasets and is simple to apply and analyse.:@0.067333:0.922614:0.509350:0.922614:0.509350:0.906207:0.067333:0.906207:0.005421:0.009598:0.004488:0.014102:0.008566:0.009647:0.003964:0.009270:0.014102:0.006551:0.006944:0.003964:0.007403:0.008566:0.009647:0.004488:0.009647:0.008336:0.005552:0.008336:0.006944:0.008566:0.005552:0.006944:0.004488:0.008336:0.009270:0.009647:0.004488:0.003964:0.006944:0.004488:0.006944:0.003964:0.014102:0.009630:0.003964:0.008566:0.004488:0.005441:0.009598:0.004488:0.008336:0.009630:0.009630:0.003964:0.007927:0.004488:0.008336:0.009270:0.009647:0.004488:0.008336:0.009270:0.008336:0.003964:0.007927:0.006944:0.008566:0.003554