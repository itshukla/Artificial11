Touchpad A:@0.176420:0.958597:0.262602:0.958597:0.262602:0.941370:0.176420:0.941370:0.008484:0.009106:0.009106:0.008189:0.009106:0.009106:0.009106:0.009123:0.003931:0.010924
rtificial Intelligence (Ver. 3.0)-XI:@0.262897:0.958597:0.489524:0.958597:0.489524:0.941370:0.262897:0.941370:0.005454:0.004553:0.003636:0.004095:0.004095:0.008189:0.003636:0.009106:0.003636:0.004553:0.004553:0.009106:0.004553:0.009106:0.003636:0.003636:0.003636:0.009106:0.009106:0.009106:0.008189:0.009106:0.004553:0.005454:0.010041:0.009106:0.004553:0.004553:0.004553:0.009106:0.004553:0.009106:0.005454:0.005749:0.011499:0.004553
440:@0.113927:0.958672:0.140411:0.958672:0.140411:0.942265:0.113927:0.942265:0.008828:0.008828:0.008828
22.  Find the Transpose of the following matrix.:@0.067333:0.058007:0.411839:0.058007:0.411839:0.041600:0.067333:0.041600:0.008828:0.008828:0.003554:0.004488:0.011972:0.007993:0.003964:0.009270:0.009647:0.004488:0.005552:0.009270:0.008566:0.004488:0.007157:0.005700:0.008336:0.009270:0.006944:0.009630:0.009598:0.006944:0.008566:0.004488:0.009295:0.005126:0.004488:0.005552:0.009270:0.008566:0.004488:0.005126:0.009598:0.003964:0.003964:0.009598:0.011841:0.003964:0.009270:0.009647:0.004488:0.014102:0.008336:0.005552:0.005700:0.003964:0.007518:0.003554
2:@0.452671:0.085285:0.461499:0.085285:0.461499:0.068878:0.452671:0.068878:0.008828
–5:@0.496892:0.085285:0.513909:0.085285:0.513909:0.068878:0.496892:0.068878:0.008189:0.008828
3:@0.555853:0.085285:0.564681:0.085285:0.564681:0.068878:0.555853:0.068878:0.008828
–1:@0.446120:0.100430:0.463137:0.100430:0.463137:0.084023:0.446120:0.084023:0.008189:0.008828
0:@0.501805:0.100430:0.510633:0.100430:0.510633:0.084023:0.501805:0.084023:0.008828
2/5:@0.547664:0.100430:0.571707:0.100430:0.571707:0.084023:0.547664:0.084023:0.008828:0.006387:0.008828
Ans.:@0.067333:0.101049:0.097665:0.101049:0.097665:0.084642:0.067333:0.084642:0.010564:0.009270:0.006944:0.003554
 :@0.097666:0.101049:0.102154:0.101049:0.102154:0.084642:0.097666:0.084642:0.004488
2:@0.150862:0.101688:0.159689:0.101688:0.159689:0.085281:0.150862:0.085281:0.008828
–1:@0.195083:0.101688:0.212100:0.101688:0.212100:0.085281:0.195083:0.085281:0.008189:0.008828
–5:@0.144310:0.116833:0.161327:0.116833:0.161327:0.100426:0.144310:0.100426:0.008189:0.008828
0:@0.199996:0.116833:0.208824:0.116833:0.208824:0.100426:0.199996:0.100426:0.008828
3:@0.144310:0.135550:0.153138:0.135550:0.153138:0.119143:0.144310:0.119143:0.008828
2/5:@0.199996:0.135550:0.224039:0.135550:0.224039:0.119143:0.199996:0.119143:0.008828:0.006387:0.008828
23.  Find the sum of A and B.:@0.067333:0.174905:0.281690:0.174905:0.281690:0.158498:0.067333:0.158498:0.008828:0.008828:0.003554:0.004488:0.011972:0.007993:0.003964:0.009270:0.009647:0.004488:0.005552:0.009270:0.008566:0.004488:0.006944:0.009270:0.014102:0.004488:0.009303:0.005126:0.004488:0.010564:0.004488:0.008336:0.009270:0.009647:0.004488:0.009385:0.003554
Ans. :@0.067333:0.205248:0.102153:0.205248:0.102153:0.188841:0.067333:0.188841:0.010564:0.009270:0.006944:0.003554:0.004488
A = :@0.134483:0.205248:0.165225:0.205248:0.165225:0.188841:0.134483:0.188841:0.010564:0.004488:0.011203:0.004488
16:@0.169622:0.195900:0.187278:0.195900:0.187278:0.179493:0.169622:0.179493:0.008828:0.008828
–10:@0.213843:0.195900:0.239688:0.195900:0.239688:0.179493:0.213843:0.179493:0.008189:0.008828:0.008828
5 :@0.169622:0.211045:0.182938:0.211045:0.182938:0.194638:0.169622:0.194638:0.008828:0.004488
    0:@0.213843:0.211045:0.240621:0.211045:0.240621:0.194638:0.213843:0.194638:0.004488:0.004488:0.004488:0.004488:0.008828
 :@0.248700:0.205248:0.253188:0.205248:0.253188:0.188841:0.248700:0.188841:0.004488
B = :@0.303174:0.205248:0.332737:0.205248:0.332737:0.188841:0.303174:0.188841:0.009385:0.004488:0.011203:0.004488
 6 :@0.337141:0.196788:0.354945:0.196788:0.354945:0.180381:0.337141:0.180381:0.004488:0.008828:0.004488
2:@0.381362:0.196788:0.390190:0.196788:0.390190:0.180381:0.381362:0.180381:0.008828
–10  8:@0.337141:0.211933:0.390190:0.211933:0.390190:0.195526:0.337141:0.195526:0.008189:0.008828:0.008828:0.004488:0.013889:0.008828
 :@0.067333:0.242746:0.071821:0.242746:0.071821:0.226339:0.067333:0.226339:0.004488
A + B = :@0.105003:0.242746:0.165307:0.242746:0.165307:0.226339:0.105003:0.226339:0.010564:0.004488:0.011203:0.004488:0.009385:0.004488:0.011203:0.004488
16:@0.169707:0.233398:0.187363:0.233398:0.187363:0.216991:0.169707:0.216991:0.008828:0.008828
–10:@0.213928:0.233398:0.239773:0.233398:0.239773:0.216991:0.213928:0.216991:0.008189:0.008828:0.008828
5 :@0.169707:0.248543:0.183022:0.248543:0.183022:0.232136:0.169707:0.232136:0.008828:0.004488
    0:@0.213928:0.248543:0.240706:0.248543:0.240706:0.232136:0.213928:0.232136:0.004488:0.004488:0.004488:0.004488:0.008828
 + :@0.248404:0.242746:0.268582:0.242746:0.268582:0.226339:0.248404:0.226339:0.004488:0.011203:0.004488
 6 :@0.272979:0.234285:0.290782:0.234285:0.290782:0.217878:0.272979:0.217878:0.004488:0.008828:0.004488
2:@0.317200:0.234285:0.326028:0.234285:0.326028:0.217878:0.317200:0.217878:0.008828
–10  8:@0.272979:0.249430:0.326028:0.249430:0.326028:0.233023:0.272979:0.233023:0.008189:0.008828:0.008828:0.004488:0.013889:0.008828
=:@0.150862:0.280244:0.162064:0.280244:0.162064:0.263836:0.150862:0.263836:0.011203
22:@0.170950:0.270896:0.188605:0.270896:0.188605:0.254489:0.170950:0.254489:0.008828:0.008828
–8:@0.215171:0.270896:0.232188:0.270896:0.232188:0.254489:0.215171:0.254489:0.008189:0.008828
–5 :@0.170950:0.286041:0.192454:0.286041:0.192454:0.269634:0.170950:0.269634:0.008189:0.008828:0.004488
  8:@0.215171:0.286041:0.232974:0.286041:0.232974:0.269634:0.215171:0.269634:0.004488:0.004488:0.008828
24.   Perform Linear Regression on the Mobile Phone Price Prediction (The dataset can be downloaded :@0.067333:0.306116:0.809607:0.306116:0.809607:0.289709:0.067333:0.289709:0.008828:0.008828:0.003554:0.004488:0.011972:0.000000:0.008564:0.008566:0.006006:0.005126:0.009598:0.005660:0.014098:0.004373:0.007714:0.003964:0.009270:0.008566:0.008336:0.005700:0.004357:0.009336:0.008566:0.009647:0.005475:0.008566:0.006944:0.006944:0.003964:0.009598:0.009281:0.004373:0.009598:0.009270:0.004373:0.005552:0.009270:0.008566:0.004373:0.014708:0.009598:0.009630:0.003964:0.003964:0.008566:0.004373:0.009172:0.009270:0.009598:0.009270:0.008566:0.004373:0.009172:0.005700:0.003964:0.007567:0.008566:0.004373:0.009172:0.005487:0.008566:0.009647:0.003964:0.007567:0.005552:0.003964:0.009598:0.009254:0.004373:0.004946:0.008582:0.009270:0.008566:0.004357:0.009647:0.008336:0.005552:0.008336:0.006944:0.008566:0.005552:0.004357:0.007567:0.008336:0.009270:0.004357:0.009630:0.008566:0.004373:0.009647:0.009598:0.011841:0.009270:0.003964:0.009368:0.008336:0.009647:0.008566:0.009647:0.004488
from :@0.105003:0.326309:0.143794:0.326309:0.143794:0.309902:0.105003:0.309902:0.005126:0.005478:0.009598:0.014102:0.004488
https://www.kaggle.com/datasets/dewangmoghe/mobile-phone-price-prediction:@0.147389:0.326309:0.733966:0.326309:0.733966:0.309902:0.147389:0.309902:0.009270:0.005552:0.005552:0.009630:0.006944:0.003554:0.006387:0.006387:0.011818:0.011841:0.011014:0.003554:0.008140:0.008336:0.009647:0.009647:0.003964:0.008566:0.003554:0.007567:0.009598:0.014102:0.006387:0.009647:0.008336:0.005552:0.008320:0.006944:0.008566:0.005552:0.006944:0.006387:0.009647:0.008566:0.011841:0.008336:0.009270:0.009647:0.014102:0.009598:0.009647:0.009270:0.008566:0.006387:0.014102:0.009598:0.009630:0.003964:0.003964:0.008566:0.006551:0.009630:0.009270:0.009598:0.009270:0.008566:0.006551:0.009630:0.005700:0.003964:0.007567:0.008566:0.006551:0.009630:0.005446:0.008566:0.009647:0.003964:0.007567:0.005552:0.003964:0.009598:0.009270
 save the :@0.733957:0.326309:0.809611:0.326309:0.809611:0.309902:0.733957:0.309902:0.008091:0.006944:0.008336:0.007750:0.008566:0.008091:0.005552:0.009270:0.008566:0.004488
file in csv format by the name of “mobile phone price prediction”. Also display few records of the :@0.105003:0.346503:0.809591:0.346503:0.809591:0.330096:0.105003:0.330096:0.004545:0.004545:0.003964:0.008566:0.004750:0.003964:0.009270:0.004766:0.007567:0.006944:0.007845:0.004766:0.005126:0.009598:0.005667:0.014102:0.008336:0.005552:0.004750:0.009630:0.007927:0.004750:0.005552:0.009270:0.008566:0.004750:0.009270:0.008336:0.014102:0.008566:0.004766:0.009303:0.005126:0.004750:0.006175:0.014102:0.009598:0.009630:0.003964:0.003964:0.008566:0.004766:0.009630:0.009270:0.009598:0.009270:0.008566:0.004750:0.009630:0.005700:0.003964:0.007567:0.008566:0.004750:0.009630:0.005470:0.008566:0.009647:0.003964:0.007567:0.005552:0.003964:0.009598:0.009270:0.005357:0.003552:0.004766:0.010564:0.003964:0.006944:0.009598:0.004766:0.009647:0.003964:0.006944:0.009630:0.003964:0.008336:0.007927:0.004766:0.005126:0.008566:0.011841:0.004750:0.005487:0.008566:0.007567:0.009598:0.005475:0.009647:0.006939:0.004750:0.009303:0.005126:0.004750:0.005552:0.009270:0.008566:0.004488
y-predict variable of testing dataset after linear regression has been performed.:@0.105003:0.366696:0.676215:0.366696:0.676215:0.350289:0.105003:0.350289:0.007927:0.006551:0.009630:0.005472:0.008566:0.009647:0.003964:0.007567:0.005552:0.004488:0.007545:0.008336:0.005700:0.003964:0.008336:0.009630:0.003964:0.008566:0.004488:0.009290:0.005126:0.004488:0.005421:0.008566:0.006944:0.005552:0.003964:0.009270:0.009647:0.004488:0.009647:0.008336:0.005552:0.008336:0.006944:0.008566:0.005552:0.004488:0.008336:0.005410:0.005421:0.008566:0.005700:0.004488:0.003964:0.003964:0.009270:0.008566:0.008336:0.005700:0.004488:0.005464:0.008566:0.009647:0.005475:0.008566:0.006944:0.006944:0.003964:0.009598:0.009270:0.004488:0.009270:0.008336:0.006944:0.004488:0.009630:0.008566:0.008566:0.009270:0.004488:0.009630:0.008566:0.006006:0.005126:0.009598:0.005660:0.014102:0.008566:0.009647:0.003554
import pandas as pd:@0.126294:0.388948:0.313005:0.388948:0.313005:0.374669:0.126294:0.374669:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
from sklearn.model_selection import train_test_split:@0.126294:0.407665:0.637293:0.407665:0.637293:0.393386:0.126294:0.393386:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
from sklearn.linear_model import LinearRegression:@0.126294:0.426382:0.607812:0.426382:0.607812:0.412103:0.126294:0.412103:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
import matplotlib.pyplot as plt:@0.126294:0.445098:0.430928:0.445098:0.430928:0.430819:0.126294:0.430819:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
# Load the dataset:@0.126294:0.463815:0.303178:0.463815:0.303178:0.449536:0.126294:0.449536:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
data = pd.read_csv('mobile phone price prediction.csv'):@0.126294:0.482532:0.666773:0.482532:0.666773:0.468253:0.126294:0.468253:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
# Extract numerical values from the 'Battery' and 'Price' columns:@0.126294:0.501248:0.765042:0.501248:0.765042:0.486969:0.126294:0.486969:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
data['Battery'] = data['Battery'].str.extract('(\d+)').astype(int):@0.126294:0.519965:0.774869:0.519965:0.774869:0.505686:0.126294:0.505686:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
data['Price'] = data['Price'].str.replace(',', '').astype(int):@0.126294:0.538682:0.735562:0.538682:0.735562:0.524403:0.126294:0.524403:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
# Select the feature and target variable:@0.126294:0.557398:0.519370:0.557398:0.519370:0.543119:0.126294:0.543119:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
X = data[['Battery']]  # Feature: Battery:@0.126294:0.576180:0.529197:0.576180:0.529197:0.561900:0.126294:0.561900:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
y = data['Price']   :@0.126294:0.594902:0.322832:0.594902:0.322832:0.580623:0.126294:0.580623:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
   :@0.322864:0.594902:0.352345:0.594902:0.352345:0.580623:0.322864:0.580623:0.009827:0.009827:0.009827
# Target: Price:@0.352350:0.594902:0.499753:0.594902:0.499753:0.580623:0.352350:0.580623:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
# Split the data into training and testing sets:@0.126298:0.613619:0.588162:0.613619:0.588162:0.599340:0.126298:0.599340:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_:@0.126298:0.632335:0.922265:0.632335:0.922265:0.618056:0.126298:0.618056:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.011054:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.011052:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.011054:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.011050:0.009827:0.011042:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.011072:0.009827:0.009827:0.011044:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.011063:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
state=42):@0.126298:0.647480:0.214741:0.647480:0.214741:0.633201:0.126298:0.633201:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
# Create and train the linear regression model:@0.126298:0.666197:0.578335:0.666197:0.578335:0.651918:0.126298:0.651918:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
model = LinearRegression():@0.126298:0.684914:0.381798:0.684914:0.381798:0.670635:0.126298:0.670635:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
model.fit(X_train, y_train):@0.126298:0.703630:0.381798:0.703630:0.381798:0.689351:0.126298:0.689351:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.004913:0.004913:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
# Predict the target variable for the testing set:@0.126298:0.722347:0.607816:0.722347:0.607816:0.708068:0.126298:0.708068:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
y_pred = model.predict(X_test):@0.126298:0.741064:0.421105:0.741064:0.421105:0.726785:0.126298:0.726785:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
# Print the first 10 rows of the actual and predicted values:@0.126298:0.759780:0.706085:0.759780:0.706085:0.745501:0.126298:0.745501:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.004913:0.004913:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
print(\First 10 actual prices vs predicted prices:\):@0.126298:0.778497:0.637297:0.778497:0.637297:0.764218:0.126298:0.764218:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
for actual, predicted in zip(y_test[:10], y_pred[:10])::@0.126298:0.797214:0.666777:0.797214:0.666777:0.782935:0.126298:0.782935:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
    :@0.126294:0.815995:0.165602:0.815995:0.165602:0.801716:0.126294:0.801716:0.009827:0.009827:0.009827:0.009827
print(f\Actual: {actual}:@0.165608:0.815995:0.656953:0.815995:0.656953:0.801716:0.165608:0.801716:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
# Plot the results:@0.126301:0.834711:0.303185:0.834711:0.303185:0.820432:0.126301:0.820432:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
plt.scatter(X_test, y_test, color='blue', label='Actual prices'):@0.126301:0.853428:0.755222:0.853428:0.755222:0.839149:0.126301:0.839149:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
plt.plot(X_test, y_pred, color='red', label='Predicted prices'):@0.126301:0.872145:0.745395:0.872145:0.745395:0.857866:0.126301:0.857866:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
plt.xlabel('Battery Power (mAh)'):@0.126301:0.890861:0.450588:0.890861:0.450588:0.876582:0.126301:0.876582:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
plt.ylabel('Price (INR)'):@0.126301:0.909578:0.371973:0.909578:0.371973:0.895299:0.126301:0.895299:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
plt.title('Battery Power vs. Price'):@0.126301:0.928295:0.480069:0.928295:0.480069:0.914016:0.126301:0.914016:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827