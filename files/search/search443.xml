plt.legend():@0.145948:0.060643:0.263871:0.060643:0.263871:0.046364:0.145948:0.046364:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
plt.savefig(\Linear_Regression.png\):@0.145948:0.079360:0.489889:0.079360:0.489889:0.065081:0.145948:0.065081:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.004913:0.004913:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
plt.show():@0.145948:0.098077:0.244217:0.098077:0.244217:0.083798:0.145948:0.083798:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
 :@0.086987:0.121859:0.096814:0.121859:0.096814:0.107580:0.086987:0.107580:0.009827
Output::@0.124657:0.118324:0.184224:0.118324:0.184224:0.101677:0.124657:0.101677:0.012415:0.009909:0.006371:0.010154:0.009909:0.006371:0.004438
First 10 actual prices vs predicted prices::@0.145948:0.140576:0.568504:0.140576:0.568504:0.126297:0.145948:0.126297:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
Actual: 28999, Predicted: 33461.01675564506:@0.145948:0.159293:0.568504:0.159293:0.568504:0.145014:0.145948:0.145014:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
Actual: 30999, Predicted: 32409.481421638382:@0.145948:0.178009:0.578331:0.178009:0.578331:0.163730:0.145948:0.163730:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
Actual: 72999, Predicted: 23646.686971582698:@0.145948:0.196726:0.578331:0.196726:0.578331:0.182447:0.145948:0.182447:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
Actual: 27990, Predicted: 35914.599201660654:@0.145948:0.215443:0.578331:0.215443:0.578331:0.201164:0.145948:0.201164:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
Actual: 11990, Predicted: 32409.481421638382:@0.145948:0.234159:0.578331:0.234159:0.578331:0.219880:0.145948:0.219880:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
Actual: 39990, Predicted: 46429.95254172747:@0.145948:0.252876:0.568504:0.252876:0.568504:0.238597:0.145948:0.238597:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
Actual: 56990, Predicted: 39419.71698168293:@0.145948:0.271593:0.568504:0.271593:0.568504:0.257314:0.145948:0.257314:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
Actual: 8199, Predicted: 32409.481421638382:@0.145948:0.290309:0.568504:0.290309:0.568504:0.276030:0.145948:0.276030:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
Actual: 59999, Predicted: 36790.87864666622:@0.145948:0.309026:0.568504:0.309026:0.568504:0.294747:0.145948:0.294747:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
Actual: 10999, Predicted: 32409.481421638382:@0.145948:0.327743:0.578331:0.327743:0.578331:0.313464:0.145948:0.313464:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
25.   Write Python program for K Means Clustering Algorithm. You may generate synthetic data for 100 loan applicants :@0.086987:0.570389:0.946389:0.570389:0.946389:0.553982:0.086987:0.553982:0.008828:0.008828:0.003554:0.004488:0.011972:0.000000:0.015297:0.005700:0.003964:0.005421:0.008566:0.004373:0.009172:0.007975:0.005552:0.009270:0.009598:0.009270:0.004373:0.009630:0.005477:0.009598:0.009647:0.005700:0.008336:0.014102:0.004373:0.005126:0.009598:0.005700:0.004373:0.009499:0.004373:0.014708:0.008566:0.008336:0.009270:0.006944:0.004373:0.010138:0.003964:0.009270:0.006944:0.005431:0.008566:0.005700:0.003964:0.009270:0.009647:0.004373:0.010564:0.003964:0.009647:0.009598:0.005700:0.003964:0.005552:0.009270:0.014102:0.003554:0.004373:0.007614:0.009598:0.009270:0.004373:0.014102:0.008336:0.007927:0.004373:0.009647:0.008566:0.009270:0.008566:0.005700:0.008336:0.005408:0.008566:0.004373:0.006944:0.007927:0.009270:0.005552:0.009270:0.008566:0.005552:0.003964:0.007567:0.004373:0.009647:0.008336:0.005552:0.008336:0.004373:0.005126:0.009598:0.005700:0.004373:0.008828:0.008828:0.008828:0.004383:0.003964:0.009383:0.008336:0.009270:0.004373:0.008336:0.009630:0.009630:0.003964:0.003964:0.007567:0.008336:0.009270:0.005552:0.006944:0.004488
with two features: ‘Annual Income’ and ‘Loan Amount’.:@0.124657:0.590582:0.515416:0.590582:0.515416:0.574175:0.124657:0.574175:0.011841:0.003964:0.005552:0.009270:0.004488:0.005552:0.011779:0.009598:0.004488:0.005126:0.008566:0.008336:0.005552:0.009270:0.005467:0.008566:0.006944:0.003554:0.004488:0.001998:0.010564:0.009270:0.009270:0.009270:0.008336:0.003964:0.004488:0.004357:0.009270:0.007567:0.009598:0.014102:0.008566:0.003751:0.004488:0.008336:0.009270:0.009647:0.004488:0.003751:0.007714:0.009365:0.008336:0.009270:0.004488:0.010564:0.014102:0.009598:0.009270:0.009270:0.005552:0.002928:0.003554
import numpy as np:@0.145948:0.612834:0.322832:0.612834:0.322832:0.598555:0.145948:0.598555:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
import pandas as pd:@0.145948:0.631551:0.332659:0.631551:0.332659:0.617272:0.145948:0.617272:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
import matplotlib.pyplot as plt:@0.145948:0.650268:0.450582:0.650268:0.450582:0.635989:0.145948:0.635989:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
from sklearn.cluster import KMeans:@0.145948:0.668984:0.480062:0.668984:0.480062:0.654705:0.145948:0.654705:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
from sklearn.preprocessing import StandardScaler:@0.145948:0.687701:0.617639:0.687701:0.617639:0.673422:0.145948:0.673422:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
# Step 1: Create synthetic data:@0.145948:0.706418:0.450582:0.706418:0.450582:0.692138:0.145948:0.692138:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
np.random.seed(42):@0.145948:0.725134:0.322832:0.725134:0.322832:0.710855:0.145948:0.710855:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
num_applicants = 100:@0.145948:0.743851:0.342486:0.743851:0.342486:0.729572:0.145948:0.729572:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
# Assume we have two features: 'Annual Income' and 'Loan Amount':@0.145948:0.762568:0.774869:0.762568:0.774869:0.748288:0.145948:0.748288:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
annual_income = np.random.normal(loc=50000, scale=15000, size=num_applicants):@0.145948:0.781284:0.902619:0.781284:0.902619:0.767005:0.145948:0.767005:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
loan_amount = np.random.normal(loc=20000, scale=7000, size=num_applicants):@0.145948:0.800001:0.873138:0.800001:0.873138:0.785722:0.145948:0.785722:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
# Combine into a DataFrame:@0.145948:0.818717:0.401447:0.818717:0.401447:0.804438:0.145948:0.804438:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
data = pd.DataFrame({:@0.145948:0.837434:0.352313:0.837434:0.352313:0.823155:0.145948:0.823155:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
    :@0.145948:0.856233:0.185256:0.856233:0.185256:0.841954:0.145948:0.841954:0.009827:0.009827:0.009827:0.009827
'Annual Income': annual_income,:@0.185262:0.856233:0.489896:0.856233:0.489896:0.841954:0.185262:0.841954:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
    :@0.145948:0.874955:0.185256:0.874955:0.185256:0.860676:0.145948:0.860676:0.009827:0.009827:0.009827:0.009827
'Loan Amount': loan_amount :@0.185262:0.874955:0.450588:0.874955:0.450588:0.860676:0.185262:0.860676:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
}):@0.499723:0.874955:0.519376:0.874955:0.519376:0.860676:0.499723:0.860676:0.009827:0.009827
# Step 2: Standardize the data:@0.145948:0.893678:0.440755:0.893678:0.440755:0.879399:0.145948:0.879399:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
scaler = StandardScaler():@0.145948:0.912395:0.391620:0.912395:0.391620:0.898115:0.145948:0.898115:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
data_scaled = scaler.fit_transform(data):@0.145948:0.931111:0.529197:0.931111:0.529197:0.916832:0.145948:0.916832:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.004913:0.004913:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827:0.009827
Practical Questions:@0.689539:0.958585:0.830620:0.958585:0.830620:0.941357:0.689539:0.941357:0.010924:0.005454:0.009106:0.008189:0.004553:0.003636:0.008189:0.009106:0.003636:0.004553:0.012742:0.009106:0.009106:0.008189:0.004553:0.003636:0.009106:0.009106:0.008189
441:@0.866633:0.958672:0.893116:0.958672:0.893116:0.942265:0.866633:0.942265:0.008828:0.008828:0.008828