Machine Learning Algorithms:@0.619414:0.958597:0.830616:0.958597:0.830616:0.941370:0.619414:0.941370:0.013643:0.009106:0.008189:0.009106:0.003636:0.009106:0.009106:0.004563:0.009106:0.009106:0.009106:0.005454:0.009106:0.003636:0.009106:0.009106:0.003665:0.010924:0.003636:0.009106:0.009106:0.005454:0.003636:0.004553:0.009106:0.013643:0.008189
327:@0.866633:0.958672:0.893116:0.958672:0.893116:0.942265:0.866633:0.942265:0.008828:0.008828:0.008828
Least Squares Method—Finding the Line of Best Fit:@0.086528:0.063162:0.557806:0.063162:0.557806:0.046403:0.086528:0.046403:0.010043:0.010633:0.010574:0.008648:0.007645:0.005424:0.011026:0.012166:0.011891:0.010574:0.007822:0.010633:0.008648:0.005424:0.018809:0.010633:0.007645:0.011832:0.012008:0.012166:0.019654:0.010220:0.005582:0.011891:0.012166:0.005582:0.011891:0.012166:0.005424:0.007645:0.011832:0.010633:0.005424:0.010043:0.005582:0.011891:0.010633:0.005424:0.012008:0.007527:0.005424:0.012598:0.010633:0.008648:0.007645:0.005424:0.010220:0.005582:0.007645
Consider the following example, where marks of 10 students are shown, which they scored after a certain number of :@0.086528:0.086116:0.945955:0.086116:0.945955:0.069709:0.086528:0.069709:0.010302:0.009761:0.009434:0.007108:0.004127:0.009811:0.008730:0.005863:0.004685:0.005716:0.009434:0.008730:0.004684:0.005290:0.009761:0.004127:0.004127:0.009761:0.012005:0.004127:0.009434:0.009811:0.004684:0.008730:0.007681:0.008500:0.014265:0.009794:0.004127:0.008730:0.003718:0.004684:0.012005:0.009434:0.008730:0.005634:0.008730:0.004684:0.014265:0.008500:0.005863:0.008304:0.007108:0.004684:0.009467:0.005290:0.004684:0.008992:0.008992:0.004684:0.007108:0.005716:0.009434:0.009811:0.008730:0.009434:0.005716:0.007108:0.004684:0.008500:0.005634:0.008730:0.004684:0.007108:0.009434:0.009761:0.012005:0.009434:0.003718:0.004684:0.012005:0.009434:0.004127:0.007730:0.009434:0.004684:0.005716:0.009434:0.008730:0.008091:0.004684:0.007108:0.007730:0.009761:0.005634:0.008730:0.009811:0.004701:0.008500:0.005585:0.005585:0.008730:0.005863:0.004684:0.008500:0.004684:0.007730:0.008730:0.006322:0.005716:0.008500:0.004127:0.009434:0.004684:0.009434:0.009434:0.014265:0.009794:0.008730:0.005863:0.004684:0.009467:0.005126:0.004488
hours of study::@0.086528:0.105047:0.196006:0.105047:0.196006:0.088640:0.086528:0.088640:0.009434:0.009761:0.009434:0.005970:0.007108:0.004651:0.009465:0.005290:0.004651:0.007108:0.005716:0.009434:0.009811:0.008091:0.003554
No. of Hours Studied:@0.391260:0.135766:0.553375:0.135766:0.553375:0.119119:0.391260:0.119119:0.012939:0.010007:0.004438:0.004520:0.009768:0.006273:0.004520:0.012546:0.010007:0.009909:0.006623:0.007206:0.004520:0.008771:0.006371:0.009909:0.010138:0.004651:0.008861:0.010138
Marks:@0.592187:0.135766:0.639552:0.135766:0.639552:0.119119:0.592187:0.119119:0.015674:0.008811:0.006519:0.009155:0.007206
2:@0.481798:0.161714:0.490626:0.161714:0.490626:0.145307:0.481798:0.145307:0.008828
44:@0.607042:0.161714:0.624697:0.161714:0.624697:0.145307:0.607042:0.145307:0.008828:0.008828
9:@0.481798:0.187663:0.490626:0.187663:0.490626:0.171256:0.481798:0.171256:0.008828
98:@0.607042:0.187663:0.624697:0.187663:0.624697:0.171256:0.607042:0.171256:0.008828:0.008828
5:@0.481798:0.213611:0.490626:0.213611:0.490626:0.197204:0.481798:0.197204:0.008828
80:@0.607042:0.213611:0.624697:0.213611:0.624697:0.197204:0.607042:0.197204:0.008828:0.008828
3:@0.481798:0.239560:0.490626:0.239560:0.490626:0.223153:0.481798:0.223153:0.008828
75:@0.607042:0.239560:0.624697:0.239560:0.624697:0.223153:0.607042:0.223153:0.008828:0.008828
7:@0.481798:0.265508:0.490626:0.265508:0.490626:0.249101:0.481798:0.249101:0.008828
70:@0.607042:0.265508:0.624697:0.265508:0.624697:0.249101:0.607042:0.249101:0.008828:0.008828
1:@0.481798:0.291456:0.490626:0.291456:0.490626:0.275049:0.481798:0.275049:0.008828
63:@0.607042:0.291456:0.624697:0.291456:0.624697:0.275049:0.607042:0.275049:0.008828:0.008828
8:@0.481798:0.317405:0.490626:0.317405:0.490626:0.300998:0.481798:0.300998:0.008828
53:@0.607042:0.317405:0.624697:0.317405:0.624697:0.300998:0.607042:0.300998:0.008828:0.008828
6:@0.481798:0.343353:0.490626:0.343353:0.490626:0.326946:0.481798:0.326946:0.008828
92:@0.607042:0.343353:0.624697:0.343353:0.624697:0.326946:0.607042:0.326946:0.008828:0.008828
2.5:@0.469416:0.369302:0.490626:0.369302:0.490626:0.352894:0.469416:0.352894:0.008828:0.003554:0.008828
71:@0.607042:0.369302:0.624697:0.369302:0.624697:0.352894:0.607042:0.352894:0.008828:0.008828
4:@0.481798:0.395250:0.490626:0.395250:0.490626:0.378843:0.481798:0.378843:0.008828
65:@0.607042:0.395250:0.624697:0.395250:0.624697:0.378843:0.607042:0.378843:0.008828:0.008828
Assuming :@0.086528:0.429211:0.163030:0.429211:0.163030:0.412804:0.086528:0.412804:0.010728:0.007108:0.007108:0.009434:0.014265:0.004127:0.009434:0.009810:0.004488
No. of Hours Studied:@0.162904:0.429211:0.327188:0.429211:0.327188:0.412564:0.162904:0.412564:0.013103:0.010171:0.004602:0.004373:0.009928:0.006437:0.004373:0.012709:0.010171:0.010073:0.006777:0.007370:0.004373:0.008938:0.006535:0.010073:0.010302:0.004815:0.009024:0.010138
 as x and :@0.327389:0.429211:0.395931:0.429211:0.395931:0.412804:0.327389:0.412804:0.004340:0.008500:0.007108:0.004340:0.007681:0.004340:0.008500:0.009434:0.009811:0.004488
Marks:@0.395804:0.429211:0.443825:0.429211:0.443825:0.412564:0.395804:0.412564:0.015838:0.008975:0.006682:0.009319:0.007206
 as y, let us learn to plot the above data on a Scatterplot using Excel.:@0.443990:0.429211:0.941444:0.429211:0.941444:0.412804:0.443990:0.412804:0.004340:0.008500:0.007108:0.004340:0.007274:0.003716:0.004340:0.004127:0.008730:0.005716:0.004340:0.009434:0.007108:0.004357:0.004127:0.008730:0.008500:0.005831:0.009434:0.004340:0.005585:0.009761:0.004340:0.009794:0.004127:0.009761:0.005716:0.004340:0.005716:0.009434:0.008730:0.004340:0.008500:0.009794:0.009761:0.007911:0.008730:0.004340:0.009811:0.008500:0.005716:0.008500:0.004340:0.009761:0.009434:0.004340:0.008500:0.004340:0.008861:0.007730:0.008500:0.005716:0.005585:0.008730:0.005863:0.009794:0.004127:0.009761:0.005716:0.004340:0.009434:0.007108:0.004127:0.009434:0.009811:0.004357:0.008451:0.007550:0.007730:0.008730:0.004127:0.003554
0:@0.289199:0.656627:0.295499:0.656627:0.295499:0.644917:0.289199:0.644917:0.006300
20:@0.283319:0.623309:0.295885:0.623309:0.295885:0.611599:0.283319:0.611599:0.006265:0.006300
40:@0.283319:0.589927:0.295885:0.589927:0.295885:0.578217:0.283319:0.578217:0.006265:0.006300
60:@0.283319:0.556608:0.295885:0.556608:0.295885:0.544898:0.283319:0.544898:0.006265:0.006300
80:@0.283319:0.523290:0.295885:0.523290:0.295885:0.511580:0.283319:0.511580:0.006265:0.006300
100:@0.277357:0.489908:0.296259:0.489908:0.296259:0.478198:0.277357:0.478198:0.006336:0.006265:0.006300
120:@0.277357:0.456589:0.296259:0.456589:0.296259:0.444880:0.277357:0.444880:0.006336:0.006265:0.006300
0:@0.303027:0.668301:0.309327:0.668301:0.309327:0.656591:0.303027:0.656591:0.006300
1:@0.348661:0.668301:0.354961:0.668301:0.354961:0.656591:0.348661:0.656591:0.006300
2:@0.394295:0.668301:0.400596:0.668301:0.400596:0.656591:0.394295:0.656591:0.006300
3:@0.439929:0.668301:0.446230:0.668301:0.446230:0.656591:0.439929:0.656591:0.006300
4:@0.485564:0.668301:0.491864:0.668301:0.491864:0.656591:0.485564:0.656591:0.006300
5:@0.531198:0.668301:0.537498:0.668301:0.537498:0.656591:0.531198:0.656591:0.006300
6:@0.576832:0.668301:0.583132:0.668301:0.583132:0.656591:0.576832:0.656591:0.006300
7:@0.622466:0.668301:0.628767:0.668301:0.628767:0.656591:0.622466:0.656591:0.006300
8:@0.668100:0.668301:0.674401:0.668301:0.674401:0.656591:0.668100:0.656591:0.006300
9:@0.713734:0.668301:0.720035:0.668301:0.720035:0.656591:0.713734:0.656591:0.006300
10:@0.756376:0.668301:0.769012:0.668301:0.769012:0.656591:0.756376:0.656591:0.006336:0.006300
Marks (Y) :@0.273331:0.571073:0.273331:0.527229:0.256413:0.527229:0.256413:0.571073:0.000000:0.000000:0.000000:0.000000:0.000000:0.000000:0.000000:0.000000:0.000000:0.056896
No. of Hours Studied (X) :@0.468604:0.683563:0.611951:0.683563:0.611951:0.670526:0.468604:0.670526:0.009747:0.007639:0.002837:0.003579:0.007639:0.004086:0.003579:0.009253:0.007639:0.007379:0.004542:0.005531:0.003579:0.006923:0.004425:0.007379:0.007678:0.003162:0.006819:0.007678:0.003071:0.003956:0.007704:0.003956:0.003566
We will also try to find the line that best fits the data i.e. the line that passes close to most of the data points. This line :@0.086528:0.729293:0.945939:0.729293:0.945939:0.712886:0.086528:0.712886:0.015071:0.008729:0.004206:0.012005:0.004127:0.004127:0.004127:0.004209:0.008500:0.004127:0.007108:0.009761:0.004209:0.005716:0.006519:0.008091:0.004193:0.005585:0.009761:0.004209:0.004627:0.004627:0.009434:0.009811:0.004193:0.005716:0.009434:0.008730:0.004209:0.004127:0.004127:0.009434:0.008730:0.004209:0.005716:0.009434:0.008500:0.005716:0.004193:0.009794:0.008730:0.007108:0.005716:0.004209:0.004627:0.004627:0.005716:0.007108:0.004209:0.005716:0.009434:0.008730:0.004209:0.009811:0.008500:0.005716:0.008500:0.004193:0.004127:0.003718:0.008730:0.003718:0.004209:0.005716:0.009434:0.008730:0.004209:0.004127:0.004127:0.009434:0.008730:0.004209:0.005716:0.009434:0.008500:0.005716:0.004193:0.009581:0.008500:0.007108:0.007108:0.008730:0.007108:0.004209:0.007730:0.004127:0.009761:0.007108:0.008730:0.004209:0.005585:0.009761:0.004209:0.014265:0.009761:0.007108:0.005716:0.004209:0.009467:0.005290:0.004209:0.005716:0.009434:0.008730:0.004209:0.009811:0.008500:0.005716:0.008500:0.004193:0.009794:0.009761:0.004127:0.009434:0.005716:0.007108:0.003718:0.004209:0.008746:0.009434:0.004127:0.007108:0.004209:0.004127:0.004127:0.009434:0.008566:0.004488
is called the ‘:@0.086528:0.748224:0.182373:0.748224:0.182373:0.731817:0.086528:0.731817:0.004127:0.007108:0.004651:0.007730:0.008500:0.004127:0.004127:0.008730:0.009811:0.004651:0.005716:0.009434:0.008730:0.004651:0.003751
Line of Best Fit:@0.182537:0.748224:0.298858:0.748224:0.298858:0.731577:0.182537:0.731577:0.008533:0.004815:0.010073:0.009024:0.004684:0.009928:0.006437:0.004684:0.010662:0.009024:0.007370:0.006535:0.004684:0.008680:0.004815:0.006371
’ or ‘:@0.299035:0.748224:0.331627:0.748224:0.331627:0.731817:0.299035:0.731817:0.003914:0.004651:0.009761:0.005863:0.004651:0.003751
Regression Line:@0.331783:0.748224:0.453962:0.748224:0.453962:0.731577:0.331783:0.731577:0.010448:0.009024:0.010302:0.006617:0.009024:0.007370:0.007370:0.004815:0.010171:0.010073:0.004684:0.008533:0.004815:0.010073:0.008861
’.:@0.454144:0.748224:0.460793:0.748224:0.460793:0.731817:0.454144:0.731817:0.003095:0.003554
Let us find the m (slope) and b (y-intercept) that suits that data:@0.086528:0.774310:0.550231:0.774310:0.550231:0.757903:0.086528:0.757903:0.007878:0.008730:0.005716:0.004651:0.009434:0.007108:0.004651:0.004627:0.004627:0.009434:0.009810:0.004651:0.005716:0.009434:0.008729:0.004651:0.014265:0.004651:0.005110:0.007108:0.004127:0.009761:0.009794:0.008730:0.005109:0.004651:0.008500:0.009434:0.009810:0.004651:0.009794:0.004651:0.005110:0.008091:0.006715:0.004127:0.009434:0.005587:0.008730:0.005642:0.007730:0.008730:0.009794:0.005716:0.005109:0.004651:0.005716:0.009434:0.008500:0.005716:0.004651:0.007108:0.009434:0.004127:0.005716:0.007108:0.004651:0.005716:0.009434:0.008500:0.005716:0.004651:0.009811:0.008500:0.005716:0.008336
y = mx + b + e:@0.086528:0.800396:0.196932:0.800396:0.196932:0.783989:0.086528:0.783989:0.008091:0.004651:0.011366:0.004651:0.014265:0.007681:0.004651:0.011366:0.004651:0.009794:0.004651:0.011366:0.004651:0.008566
Step 1::@0.086528:0.826483:0.136172:0.826483:0.136172:0.810076:0.086528:0.810076:0.008336:0.005587:0.008730:0.009794:0.004651:0.008992:0.003554
 :@0.136329:0.826483:0.140817:0.826483:0.140817:0.810076:0.136329:0.810076:0.004488
Type the given data in :@0.140981:0.826483:0.308511:0.826483:0.308511:0.810076:0.140981:0.810076:0.007842:0.008091:0.009794:0.008730:0.004651:0.005716:0.009434:0.008730:0.004651:0.009811:0.004127:0.007912:0.008730:0.009434:0.004651:0.009811:0.008500:0.005716:0.008500:0.004651:0.004127:0.009434:0.004488
Excel:@0.308644:0.826483:0.348151:0.826483:0.348151:0.809836:0.308644:0.809836:0.008877:0.008929:0.008025:0.009024:0.004651
.:@0.348315:0.826483:0.351869:0.826483:0.351869:0.810076:0.348315:0.810076:0.003554
Step 2::@0.086528:0.852569:0.136172:0.852569:0.136172:0.836162:0.086528:0.836162:0.008336:0.005587:0.008730:0.009794:0.004651:0.008992:0.003554
 Select x and y. Click on :@0.136329:0.852569:0.312618:0.852569:0.312618:0.836162:0.136329:0.836162:0.004651:0.008861:0.008730:0.004127:0.008730:0.007730:0.005715:0.004651:0.007681:0.004651:0.008500:0.009434:0.009810:0.004651:0.007072:0.003718:0.004651:0.010302:0.004127:0.004127:0.007730:0.008303:0.004651:0.009761:0.009434:0.004488
Insert Chart:@0.312774:0.852569:0.405876:0.852569:0.405876:0.835922:0.312774:0.835922:0.005356:0.010073:0.007370:0.009024:0.007152:0.006535:0.004684:0.010384:0.010023:0.008975:0.007154:0.006371
 :@0.406040:0.852569:0.410527:0.852569:0.410527:0.836162:0.406040:0.836162:0.004488
→:@0.410699:0.852178:0.426864:0.852178:0.426864:0.836717:0.410699:0.836717:0.016165
 select the first scatter plot option.:@0.427019:0.852569:0.679774:0.852569:0.679774:0.836162:0.427019:0.836162:0.004651:0.007108:0.008730:0.004127:0.008730:0.007730:0.005715:0.004651:0.005716:0.009434:0.008729:0.004651:0.004627:0.004627:0.005970:0.007108:0.005716:0.004651:0.007108:0.007730:0.008500:0.005716:0.005587:0.008730:0.005863:0.004651:0.009794:0.004127:0.009761:0.005716:0.004651:0.009761:0.009794:0.005716:0.004127:0.009761:0.009434:0.003554