Touchpad Artificial Intelligence (Ver. 3.0)-XI:@0.176420:0.958597:0.488648:0.958597:0.488648:0.941370:0.176420:0.941370:0.008189:0.009106:0.009106:0.008189:0.009106:0.009106:0.009106:0.009106:0.003662:0.010924:0.005454:0.004553:0.003636:0.004095:0.004095:0.008189:0.003636:0.009106:0.003636:0.004553:0.004553:0.009106:0.004553:0.009106:0.003636:0.003636:0.003636:0.009106:0.009106:0.009106:0.008189:0.009106:0.004553:0.005454:0.010040:0.009106:0.004553:0.004553:0.004553:0.009106:0.004553:0.009106:0.005454:0.005749:0.011499:0.004553
230:@0.113927:0.958672:0.140411:0.958672:0.140411:0.942265:0.113927:0.942265:0.008828:0.008828:0.008828
Accuracy =  :@0.285055:0.069215:0.376019:0.069215:0.376019:0.052808:0.285055:0.052808:0.010728:0.007730:0.007730:0.009434:0.005863:0.008500:0.007730:0.008091:0.004651:0.011366:0.004651:0.004488
Number of correctly classified instances:@0.397278:0.058259:0.682511:0.058259:0.682511:0.041852:0.397278:0.041852:0.012251:0.009270:0.014102:0.009630:0.008566:0.005700:0.004488:0.009296:0.005126:0.004488:0.007567:0.009598:0.005700:0.005469:0.008566:0.007567:0.005552:0.003964:0.007927:0.004488:0.007567:0.003964:0.008336:0.006944:0.006944:0.003964:0.005126:0.003964:0.008566:0.009647:0.004488:0.003964:0.009270:0.006944:0.005552:0.008336:0.009270:0.007567:0.008566:0.006944
Total number of instances:@0.447313:0.080762:0.632486:0.080762:0.632486:0.064355:0.447313:0.064355:0.006894:0.009598:0.005552:0.008336:0.003964:0.004488:0.009270:0.009270:0.014102:0.009630:0.008566:0.005700:0.004488:0.009290:0.005126:0.004488:0.003964:0.009270:0.006944:0.005552:0.008336:0.009270:0.007567:0.008566:0.006944
• •:@0.074408:0.109220:0.074408:0.109220:0.074408:0.093760:0.074408:0.093760:0.004095:-0.011628:0.007534
Confusion matrix::@0.099630:0.109611:0.237157:0.109611:0.237157:0.092965:0.099630:0.092965:0.010220:0.010007:0.009909:0.006273:0.009909:0.007206:0.004651:0.010007:0.009909:0.004520:0.015002:0.008811:0.006371:0.006600:0.004651:0.009041:0.004438
 A confusion matrix provides a breakdown of correct and incorrect classifications for each class.:@0.237157:0.109611:0.921045:0.109611:0.921045:0.093204:0.237157:0.093204:0.004488:0.010564:0.004488:0.007567:0.009598:0.009270:0.005126:0.009270:0.006944:0.003964:0.009598:0.009270:0.004488:0.014102:0.008336:0.005552:0.005700:0.003964:0.007518:0.004488:0.009630:0.005469:0.009598:0.007845:0.003964:0.009647:0.008566:0.006944:0.004488:0.008336:0.004488:0.009630:0.005475:0.008566:0.008336:0.007920:0.009647:0.009598:0.011841:0.009270:0.004488:0.009290:0.005126:0.004488:0.007567:0.009598:0.005700:0.005469:0.008566:0.007567:0.005552:0.004488:0.008336:0.009270:0.009647:0.004488:0.003964:0.009270:0.007567:0.009598:0.005700:0.005457:0.008566:0.007567:0.005552:0.004488:0.007567:0.003964:0.008336:0.006944:0.006944:0.003964:0.004545:0.004545:0.007567:0.008336:0.005552:0.003964:0.009598:0.009270:0.006944:0.004488:0.005126:0.009598:0.005700:0.004488:0.008566:0.008336:0.007567:0.009270:0.004488:0.007567:0.003964:0.008336:0.006944:0.006944:0.003554
Predicted Negative:@0.399833:0.138789:0.547053:0.138789:0.547053:0.122143:0.399833:0.122143:0.010056:0.006458:0.008861:0.010138:0.004651:0.007862:0.006315:0.008861:0.010138:0.004520:0.012939:0.008861:0.010138:0.008811:0.006371:0.004651:0.008728:0.008861
Predicted Positive:@0.585512:0.138789:0.723422:0.138789:0.723422:0.122143:0.585512:0.122143:0.010056:0.006458:0.008861:0.010138:0.004651:0.007862:0.006315:0.008861:0.010138:0.004520:0.009573:0.010007:0.007206:0.004651:0.006371:0.004651:0.008730:0.008861
Actual Negative:@0.247303:0.162289:0.361663:0.162289:0.361663:0.145882:0.247303:0.145882:0.010564:0.007567:0.005552:0.009270:0.008336:0.003964:0.004488:0.012251:0.008566:0.009647:0.008336:0.005552:0.003964:0.007739:0.008566
True Negative (TN):@0.397048:0.162289:0.532059:0.162289:0.532059:0.145882:0.397048:0.145882:0.007157:0.005700:0.009270:0.008566:0.004488:0.012251:0.008566:0.009647:0.008336:0.005552:0.003964:0.007735:0.008566:0.004488:0.004946:0.008582:0.012251:0.004946
False Positive (FP):@0.567545:0.162289:0.693688:0.162289:0.693688:0.145882:0.567545:0.145882:0.007390:0.008336:0.003964:0.006944:0.008566:0.004488:0.008567:0.009598:0.006944:0.003964:0.005552:0.003964:0.007757:0.008566:0.004488:0.004946:0.007993:0.009172:0.004946
Actual Positive:@0.247303:0.185789:0.351946:0.185789:0.351946:0.169382:0.247303:0.169382:0.010564:0.007567:0.005552:0.009270:0.008336:0.003964:0.004488:0.008559:0.009598:0.006944:0.003964:0.005552:0.003964:0.007757:0.008566
False Negative (FN):@0.397048:0.185789:0.535988:0.185789:0.535988:0.169382:0.397048:0.169382:0.007390:0.008336:0.003964:0.006944:0.008566:0.004488:0.012251:0.008566:0.009647:0.008336:0.005552:0.003964:0.007747:0.008566:0.004488:0.004946:0.007993:0.012251:0.004946
True Positive (TP):@0.567545:0.185789:0.689760:0.185789:0.689760:0.169382:0.567545:0.169382:0.007157:0.005700:0.009270:0.008566:0.004488:0.008556:0.009598:0.006944:0.003964:0.005552:0.003964:0.007758:0.008566:0.004488:0.004946:0.008582:0.009172:0.004946
• •:@0.074415:0.217796:0.074415:0.217796:0.074415:0.202335:0.074415:0.202335:0.004095:-0.011628:0.007534
  Precision::@0.099631:0.218188:0.173730:0.218188:0.173730:0.201541:0.099631:0.201541:0.004520:-0.004520:0.010056:0.006458:0.008861:0.007862:0.004651:0.007206:0.004651:0.010007:0.009909:0.004438
 Precision measures the accuracy of positive predictions. It is the ratio of correctly predicted positive :@0.173740:0.218188:0.926320:0.218188:0.926320:0.201781:0.173740:0.201781:0.006502:0.009172:0.005478:0.008566:0.007567:0.003964:0.006944:0.003964:0.009598:0.009270:0.006502:0.014102:0.008566:0.008336:0.006944:0.009270:0.005482:0.008566:0.006944:0.006502:0.005552:0.009270:0.008566:0.006491:0.008336:0.007567:0.007567:0.009270:0.005700:0.008336:0.007567:0.007927:0.006476:0.009301:0.005126:0.006494:0.009630:0.009598:0.006944:0.003964:0.005552:0.003964:0.007757:0.008566:0.006494:0.009630:0.005477:0.008566:0.009647:0.003964:0.007567:0.005552:0.003964:0.009598:0.009270:0.006944:0.003554:0.006494:0.004357:0.005552:0.006502:0.003964:0.006944:0.006502:0.005552:0.009270:0.008566:0.006492:0.005700:0.008336:0.005552:0.003964:0.009598:0.006486:0.009301:0.005126:0.006502:0.007567:0.009598:0.005700:0.005470:0.008566:0.007567:0.005552:0.003964:0.007927:0.006491:0.009630:0.005477:0.008566:0.009647:0.003964:0.007567:0.005421:0.008566:0.009647:0.006492:0.009630:0.009598:0.006944:0.003964:0.005552:0.003964:0.007755:0.008566:0.004488
observations to the total predicted positives.:@0.099629:0.237119:0.420585:0.237119:0.420585:0.220712:0.099629:0.220712:0.009598:0.009630:0.006944:0.008566:0.006351:0.007549:0.008336:0.005552:0.003964:0.009598:0.009270:0.006944:0.004488:0.005421:0.009598:0.004488:0.005552:0.009270:0.008566:0.004488:0.005415:0.009598:0.005552:0.008336:0.003964:0.004488:0.009630:0.005472:0.008566:0.009647:0.003964:0.007567:0.005420:0.008566:0.009647:0.004488:0.009630:0.009598:0.006944:0.003964:0.005552:0.003964:0.007752:0.008566:0.006944:0.003554
 :@0.066874:0.266942:0.071362:0.266942:0.071362:0.250535:0.066874:0.250535:0.004488
 :@0.104544:0.266942:0.109032:0.266942:0.109032:0.250535:0.104544:0.250535:0.004488
 :@0.160230:0.266942:0.164718:0.266942:0.164718:0.250535:0.160230:0.250535:0.004488
 :@0.206089:0.266942:0.210576:0.266942:0.210576:0.250535:0.206089:0.250535:0.004488
Precision =  :@0.284704:0.266942:0.375848:0.266942:0.375848:0.250535:0.284704:0.250535:0.009336:0.005634:0.008730:0.007730:0.004127:0.007108:0.004127:0.009761:0.009434:0.004651:0.011366:0.004651:0.004488
TP:@0.400771:0.255987:0.418525:0.255987:0.418525:0.239580:0.400771:0.239580:0.008582:0.009172
TP + FP:@0.382100:0.278490:0.437196:0.278490:0.437196:0.262083:0.382100:0.262083:0.008582:0.009172:0.004488:0.011203:0.004488:0.007993:0.009172
 :@0.066874:0.303762:0.071362:0.303762:0.071362:0.287354:0.066874:0.287354:0.004488
Precision matrix would be most appropriate to use when the cost of false positives is high.:@0.099631:0.303762:0.748242:0.303762:0.748242:0.287354:0.099631:0.287354:0.009172:0.005478:0.008566:0.007567:0.003964:0.006944:0.003964:0.009598:0.009270:0.004488:0.014102:0.008336:0.005552:0.005700:0.003964:0.007518:0.004488:0.011789:0.009598:0.009270:0.003964:0.009647:0.004488:0.009630:0.008566:0.004488:0.014102:0.009598:0.006944:0.005552:0.004488:0.008336:0.009630:0.009630:0.005470:0.009598:0.009630:0.005700:0.003964:0.008336:0.005415:0.008566:0.004488:0.005420:0.009598:0.004488:0.009270:0.006944:0.008566:0.004488:0.011841:0.009270:0.008566:0.009270:0.004488:0.005552:0.009270:0.008566:0.004488:0.007567:0.009598:0.006944:0.005552:0.004488:0.009283:0.005126:0.004488:0.005126:0.008336:0.003964:0.006944:0.008566:0.004488:0.009630:0.009598:0.006944:0.003964:0.005552:0.003964:0.007757:0.008566:0.006944:0.004488:0.003964:0.006944:0.004488:0.009270:0.003964:0.009647:0.009270:0.003554
Before evaluating the metrics, you need to first import it by using the following code::@0.066874:0.326270:0.679832:0.326270:0.679832:0.309863:0.066874:0.309863:0.009385:0.008566:0.005126:0.009598:0.005480:0.008566:0.004488:0.008566:0.007547:0.008336:0.003964:0.009270:0.008336:0.005552:0.003964:0.009270:0.009647:0.004488:0.005552:0.009270:0.008566:0.004488:0.014102:0.008566:0.005552:0.005700:0.003964:0.007567:0.006944:0.003554:0.004488:0.007829:0.009598:0.009270:0.004488:0.009270:0.008566:0.008566:0.009647:0.004488:0.005413:0.009598:0.004488:0.005126:0.003964:0.005806:0.006944:0.005552:0.004488:0.003964:0.014102:0.009630:0.009598:0.006173:0.005552:0.004488:0.003964:0.005552:0.004488:0.009630:0.007927:0.004488:0.009270:0.006944:0.003964:0.009270:0.009647:0.004488:0.005552:0.009270:0.008566:0.004488:0.005126:0.009598:0.003964:0.003964:0.009598:0.011841:0.003964:0.009270:0.009647:0.004488:0.007567:0.009598:0.009647:0.008566:0.003554
from sklearn import metrics:@0.104544:0.352309:0.374129:0.352309:0.374129:0.338030:0.104544:0.338030:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
In Python, the metrics.precision_score() method is used to calculate the precision of a classification model in Python :@0.066874:0.371276:0.926308:0.371276:0.926308:0.354869:0.066874:0.354869:0.004357:0.009270:0.005970:0.009172:0.007975:0.005552:0.009270:0.009598:0.009270:0.003554:0.005962:0.005552:0.009270:0.008566:0.005965:0.014102:0.008566:0.005552:0.005700:0.003964:0.007567:0.006944:0.003554:0.009630:0.005477:0.008566:0.007567:0.003964:0.006944:0.003964:0.009598:0.009270:0.006797:0.006944:0.007567:0.009598:0.005488:0.008566:0.004946:0.004946:0.005962:0.014102:0.008566:0.005552:0.009270:0.009598:0.009647:0.005968:0.003964:0.006944:0.005978:0.009270:0.006944:0.008566:0.009647:0.005971:0.005421:0.009598:0.005970:0.007567:0.008336:0.003964:0.007567:0.009270:0.003964:0.008336:0.005416:0.008566:0.005970:0.005552:0.009270:0.008566:0.005967:0.009630:0.005475:0.008566:0.007567:0.003964:0.006944:0.003964:0.009598:0.009270:0.005978:0.009300:0.005126:0.005970:0.008336:0.005968:0.007567:0.003964:0.008336:0.006944:0.006944:0.003964:0.005126:0.003964:0.007567:0.008336:0.005552:0.003964:0.009598:0.009270:0.005978:0.014102:0.009598:0.009647:0.008566:0.003964:0.005975:0.003964:0.009270:0.005971:0.009172:0.007975:0.005552:0.009270:0.009598:0.009270:0.004488
using the sklearn library.:@0.066874:0.390207:0.242103:0.390207:0.242103:0.373800:0.066874:0.373800:0.009270:0.006944:0.003964:0.009270:0.009647:0.004488:0.005552:0.009270:0.008566:0.004488:0.006944:0.008140:0.003964:0.008566:0.008336:0.005664:0.009270:0.004488:0.003964:0.003964:0.009630:0.005700:0.008336:0.006343:0.006908:0.003554
Let us now evaluate the metrics. :@0.066874:0.412710:0.301880:0.412710:0.301880:0.396303:0.066874:0.396303:0.007714:0.008566:0.005552:0.004488:0.009270:0.006944:0.004488:0.009270:0.009598:0.011841:0.004488:0.008566:0.007532:0.008336:0.003964:0.009270:0.008336:0.005418:0.008566:0.004488:0.005552:0.009270:0.008566:0.004488:0.014102:0.008566:0.005552:0.005700:0.003964:0.007567:0.006944:0.003554:0.004488
Program 63: To evaluate the metrics of the IRIS dataset after KNN classification:@0.080796:0.442369:0.690414:0.442369:0.690414:0.425722:0.080796:0.425722:0.010056:0.006458:0.010007:0.010138:0.006519:0.008811:0.015002:0.004520:0.009417:0.009417:0.004438:0.004520:0.008137:0.010007:0.004520:0.008861:0.008631:0.008811:0.004651:0.009909:0.008811:0.006315:0.008861:0.004520:0.006371:0.009860:0.008861:0.004520:0.015002:0.008861:0.006371:0.006586:0.004651:0.007862:0.007206:0.004520:0.009763:0.006273:0.004520:0.006371:0.009860:0.008861:0.004520:0.005192:0.010695:0.005192:0.009188:0.004520:0.010138:0.008811:0.006371:0.008811:0.007206:0.008861:0.006371:0.004520:0.008811:0.006589:0.006309:0.008861:0.006519:0.004520:0.010629:0.012939:0.012939:0.004520:0.007862:0.004651:0.008811:0.007206:0.007206:0.004651:0.006273:0.004651:0.007862:0.008811:0.006371:0.004651:0.010007:0.009909
from sklearn.model_selection import train_test_split:@0.104544:0.470730:0.623895:0.470730:0.623895:0.456451:0.104544:0.456451:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
from sklearn.datasets import load_iris:@0.104544:0.493763:0.484026:0.493763:0.484026:0.479484:0.104544:0.479484:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
from sklearn.neighbors import KNeighborsClassifier:@0.104544:0.516796:0.603914:0.516796:0.603914:0.502517:0.104544:0.502517:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
from sklearn import metrics:@0.104544:0.539829:0.374129:0.539829:0.374129:0.525550:0.104544:0.525550:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
# load dataset:@0.104544:0.562862:0.244250:0.562862:0.244250:0.548583:0.104544:0.548583:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
iris = load_iris():@0.104544:0.585895:0.284213:0.585895:0.284213:0.571616:0.104544:0.571616:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
# separate the data into features and target:@0.104544:0.608928:0.543970:0.608928:0.543970:0.594649:0.104544:0.594649:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
X = iris.data:@0.104544:0.631961:0.234259:0.631961:0.234259:0.617682:0.104544:0.617682:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
y = iris.target:@0.104544:0.654994:0.254241:0.654994:0.254241:0.640715:0.104544:0.640715:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
# Split the data: 80% for training, 20% for testing:@0.104544:0.678027:0.613905:0.678027:0.613905:0.663748:0.104544:0.663748:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_:@0.104544:0.699267:0.921716:0.699267:0.921716:0.684988:0.104544:0.684988:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.012251:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.012251:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.012251:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.012251:0.009991:0.012251:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.012251:0.009991:0.009991:0.012251:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.012251:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
state=1):@0.104544:0.716937:0.184306:0.716937:0.184306:0.702658:0.104544:0.702658:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
# Splitting the data into training and testing sets (80% training, 20% testing):@0.104544:0.738177:0.893644:0.738177:0.893644:0.723898:0.104544:0.723898:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_:@0.104544:0.759418:0.921716:0.759418:0.921716:0.745139:0.104544:0.745139:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.012251:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.012251:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.012251:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.012251:0.009991:0.012251:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.012251:0.009991:0.009991:0.012251:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.012251:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
state=1):@0.104544:0.777087:0.184306:0.777087:0.184306:0.762808:0.104544:0.762808:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
# Create a KNN classifier with 3 neighbors:@0.104544:0.799590:0.523989:0.799590:0.523989:0.785311:0.104544:0.785311:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
knn = KNeighborsClassifier(n_neighbors=3):@0.104544:0.822093:0.513998:0.822093:0.513998:0.807814:0.104544:0.807814:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
# Train the KNN classifier on the training data:@0.104544:0.844596:0.573942:0.844596:0.573942:0.830317:0.104544:0.830317:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
knn.fit(X_train, y_train):@0.104544:0.867099:0.354147:0.867099:0.354147:0.852820:0.104544:0.852820:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
# Use the trained classifier to make predictions on the test data:@0.104544:0.889602:0.753774:0.889602:0.753774:0.875323:0.104544:0.875323:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827
y_pred = knn.predict(X_test):@0.104544:0.912105:0.384119:0.912105:0.384119:0.897826:0.104544:0.897826:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009991:0.009827